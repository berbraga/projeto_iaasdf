# üöÄ Guia de Uso de GPU

Este guia explica como configurar e usar GPU para acelerar o treinamento dos modelos de classifica√ß√£o.

## üìã Pr√©-requisitos

### 1. Verificar se sua GPU suporta CUDA

Para usar GPU com PyTorch, voc√™ precisa de uma GPU NVIDIA com suporte a CUDA. Verifique se sua GPU √© compat√≠vel visitando: https://developer.nvidia.com/cuda-gpus

### 2. Instalar CUDA Toolkit

1. **Baixar CUDA Toolkit**: Acesse https://developer.nvidia.com/cuda-downloads
2. **Instalar**: Siga as instru√ß√µes para sua plataforma (Windows/Linux)
3. **Verificar instala√ß√£o**: Abra o terminal e execute:
   ```bash
   nvcc --version
   ```

### 3. Instalar PyTorch com suporte CUDA

O projeto j√° est√° configurado para detectar automaticamente GPU. Voc√™ s√≥ precisa instalar o PyTorch com suporte CUDA.

#### Op√ß√£o A: Instala√ß√£o via pip (Recomendado)

**Para CUDA 11.8:**
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

**Para CUDA 12.1:**
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

**Para CUDA 12.4:**
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124
```

#### Op√ß√£o B: Instala√ß√£o via requirements.txt

O arquivo `requirements.txt` j√° instala PyTorch com suporte CUDA por padr√£o. Basta executar:

```bash
pip install -r requirements.txt
```

**Nota**: Se voc√™ n√£o tiver CUDA instalado, o PyTorch ser√° instalado na vers√£o CPU. Para for√ßar instala√ß√£o CPU, use:
```bash
pip install -r requirements-cpu.txt
```

## ‚úÖ Verificar se GPU est√° dispon√≠vel

Crie um script de teste ou execute no Python:

```python
import torch

print(f"PyTorch vers√£o: {torch.__version__}")
print(f"CUDA dispon√≠vel: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"Vers√£o CUDA: {torch.version.cuda}")
    print(f"Nome da GPU: {torch.cuda.get_device_name(0)}")
    print(f"Mem√≥ria GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
else:
    print("‚ö†Ô∏è  GPU n√£o dispon√≠vel. O treinamento usar√° CPU.")
```

Ou execute o script de verifica√ß√£o do projeto:

```bash
python verificar_instalacao.py
```

## üéØ Como o Projeto Usa GPU

O projeto **detecta automaticamente** se h√° GPU dispon√≠vel e a usa quando poss√≠vel. Voc√™ n√£o precisa fazer nenhuma configura√ß√£o adicional!

### Detec√ß√£o Autom√°tica

Ambos os scripts principais (`main.py` e `main_crops.py`) j√° fazem a detec√ß√£o:

```python
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"GPU est√° {'dispon√≠vel' if device == 'cuda' else 'N√ÉO dispon√≠vel'}")
print(f"Usando dispositivo: {device}\n")
```

### O que √© movido para GPU

- ‚úÖ **Modelo**: O modelo √© movido para GPU com `.to(device)`
- ‚úÖ **Dados de treinamento**: Os batches s√£o movidos para GPU durante o treinamento
- ‚úÖ **Dados de valida√ß√£o**: Os batches s√£o movidos para GPU durante a valida√ß√£o

## üöÄ Executando o Projeto com GPU

### 1. Classifica√ß√£o de P√°ssaros

```bash
python main.py
```

O script detectar√° automaticamente a GPU e usar√° se dispon√≠vel.

### 2. Classifica√ß√£o de Culturas Agr√≠colas

```bash
python main_crops.py
```

O script detectar√° automaticamente a GPU e usar√° se dispon√≠vel.

## üìä Verificando o Uso de GPU Durante Treinamento

### Windows (Task Manager)

1. Abra o **Gerenciador de Tarefas** (Ctrl + Shift + Esc)
2. V√° para a aba **Desempenho**
3. Selecione sua GPU
4. Monitore o uso durante o treinamento

### Linux (nvidia-smi)

Execute em um terminal separado:

```bash
watch -n 1 nvidia-smi
```

Isso atualizar√° a cada segundo mostrando:
- Uso de mem√≥ria GPU
- Utiliza√ß√£o da GPU (%)
- Processos em execu√ß√£o

### Python (Durante execu√ß√£o)

Adicione este c√≥digo no seu script para monitorar:

```python
import torch

if torch.cuda.is_available():
    print(f"Mem√≥ria GPU alocada: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB")
    print(f"Mem√≥ria GPU reservada: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB")
```

## ‚öôÔ∏è Otimiza√ß√µes para GPU

### Aumentar Batch Size

Com GPU, voc√™ pode aumentar o `batch_size` para acelerar o treinamento:

**Em `main.py`:**
```python
batch_size = 128  # Aumente de 64 para 128 ou mais (depende da mem√≥ria GPU)
```

**Em `main_crops.py`:**
```python
batch_size = 64  # Aumente de 32 para 64 ou mais (depende da mem√≥ria GPU)
```

**Aten√ß√£o**: Aumente gradualmente e monitore o uso de mem√≥ria. Se der erro de "out of memory", reduza o batch_size.

### Usar Mixed Precision (Opcional)

Para GPUs modernas (Tensor Cores), voc√™ pode usar precis√£o mista para acelerar ainda mais:

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

# No loop de treinamento:
with autocast():
    outputs = modelo(inputs)
    loss = criterio(outputs, targets)

scaler.scale(loss).backward()
scaler.step(otimizador)
scaler.update()
```

## üêõ Solu√ß√£o de Problemas

### Problema: "CUDA out of memory"

**Solu√ß√£o:**
1. Reduza o `batch_size` no arquivo de configura√ß√£o
2. Reduza o n√∫mero de imagens carregadas
3. Feche outros programas que usam GPU

### Problema: GPU n√£o √© detectada

**Verifica√ß√µes:**
1. ‚úÖ CUDA Toolkit instalado?
2. ‚úÖ PyTorch com suporte CUDA instalado?
3. ‚úÖ Drivers NVIDIA atualizados?
4. ‚úÖ GPU compat√≠vel com CUDA?

**Teste:**
```python
import torch
print(torch.cuda.is_available())  # Deve retornar True
```

### Problema: Treinamento mais lento na GPU

**Poss√≠veis causas:**
1. Dataset muito pequeno (overhead de transfer√™ncia CPU‚ÜíGPU)
2. Batch size muito pequeno
3. GPU antiga ou com pouca mem√≥ria

**Solu√ß√£o:** Para datasets pequenos, CPU pode ser mais r√°pida. Use GPU para datasets maiores.

## üìù Notas Importantes

- ‚ö†Ô∏è **Mem√≥ria GPU**: Monitore o uso de mem√≥ria. Se exceder, reduza o batch_size
- ‚ö†Ô∏è **Compatibilidade**: Certifique-se de que a vers√£o do CUDA Toolkit corresponde √† vers√£o do PyTorch
- ‚úÖ **Fallback autom√°tico**: Se GPU n√£o estiver dispon√≠vel, o projeto usa CPU automaticamente
- ‚úÖ **Sem configura√ß√£o extra**: O projeto j√° est√° configurado para usar GPU quando dispon√≠vel

## üîó Links √öteis

- [PyTorch Installation Guide](https://pytorch.org/get-started/locally/)
- [CUDA Toolkit Downloads](https://developer.nvidia.com/cuda-downloads)
- [NVIDIA GPU Compatibility](https://developer.nvidia.com/cuda-gpus)


